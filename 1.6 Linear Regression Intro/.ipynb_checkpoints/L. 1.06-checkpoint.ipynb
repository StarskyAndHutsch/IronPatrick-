{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWi42fZNRGQE"
   },
   "source": [
    "# Lesson 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vc-6GOSXRGQG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXjkVIledzqv",
    "outputId": "d2b7b926-0b37-4765-e097-5b3b2ca9df5b"
   },
   "outputs": [],
   "source": [
    "# generating an array of x values\n",
    "x = np.arange(0,10,1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "ve8_Nk6hd7lg",
    "outputId": "e14b3ff0-4846-4a55-9354-30a574b36679"
   },
   "outputs": [],
   "source": [
    "y = 0 + 1 * x\n",
    "y2 = 3 + 1 * x \n",
    "y3 = -1 + 1 * x\n",
    "#here we are changing the y-intercept, which controls the height of the line\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.plot(x,y2)\n",
    "plt.plot(x,y3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "jHptCfiDd9bQ",
    "outputId": "1932156f-0f74-4d14-8172-41dc598011d3"
   },
   "outputs": [],
   "source": [
    "y = 0 + x \n",
    "y2 = 0 + 2*x \n",
    "y3 = 0 + -3*x\n",
    "#here we are changing the gradient (aka coefficient), which controls the slope of the line\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.plot(x,y2)\n",
    "plt.plot(x,y3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97Q-RqHY2SRv"
   },
   "outputs": [],
   "source": [
    "#The whole goal of Linear Regression is to find the \"best\" intercept and slope to \"fit\" our data!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2sGJkxDRGQJ"
   },
   "outputs": [],
   "source": [
    "# apply linear regression on the following data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "tLZzo8ExRGQJ",
    "outputId": "371335fd-9498-44fa-cb1c-2cb739347d78"
   },
   "outputs": [],
   "source": [
    "reg_data = pd.read_csv('regression_data.csv')\n",
    "reg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQvtB9nf1lj3"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "hF9wSjb5S1TE",
    "outputId": "752f21d1-eb56-4f49-a97a-1c20f211c972"
   },
   "outputs": [],
   "source": [
    "#let's pick the AVGGIFT variable as the one we think is the most explanatory\n",
    "sns.scatterplot(x='AVGGIFT',y='TARGET_D',data=reg_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['TARGET_D'].corr(reg_data['AVGGIFT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7LGIStxifyc"
   },
   "outputs": [],
   "source": [
    "y = reg_data['TARGET_D']\n",
    "X = reg_data[['AVGGIFT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSH1fK5JUBf9"
   },
   "outputs": [],
   "source": [
    "# to perform the linear regression we'll use the sklearn implementation of linear regression\n",
    "# we will use sklearn a lot\n",
    "\n",
    "# we first create the model. This just tells python to be ready to use a linear model, it does not actually compute anything yet\n",
    "\n",
    "lm = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BtK1TjBQilPF",
    "outputId": "4ce22057-329a-469f-a96a-ba15cc68de71"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# we now \"fit\" (a.k.a. \"train\") the model in our data\n",
    "# linear regression picks the line (i.e. the intercept and the gradient) that best \"fits\" our data\n",
    "# we will get to the meaning of \"fitting the data\" in a second\n",
    "\n",
    "lm.fit(X,y)\n",
    "print(lm.intercept_)\n",
    "print(lm.coef_) # coefficients is an array because later we will see we can have more than one dimension for our gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "5TmpVgIDi1gl",
    "outputId": "283aa0f4-5d97-45d5-f121-985469451d58"
   },
   "outputs": [],
   "source": [
    "#let's visualize this result\n",
    "regression_line = lm.intercept_ + lm.coef_[0]*reg_data['AVGGIFT']\n",
    "plt.plot(reg_data['AVGGIFT'], regression_line, c = 'orange')\n",
    "sns.scatterplot(x='AVGGIFT',y='TARGET_D',data=reg_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHe8F43bh7Y8",
    "outputId": "96fc52a0-b1d9-4bea-f572-c117e51247b7"
   },
   "outputs": [],
   "source": [
    "#we can use this model to predict new or unseen datapoints\n",
    "lm.predict([[10],[20],[35],[55]])\n",
    "#what does this mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wjI8Qh4iVJG",
    "outputId": "75ad3c3a-1db9-4939-c832-79c291c5afbd"
   },
   "outputs": [],
   "source": [
    "#the score is not great, but we have not performed any data preparation yet\n",
    "print(\"R2-score is \", lm.score(X,y))\n",
    "\n",
    "y_pred = lm.predict(X)\n",
    "print(\"mean squared error (MSE) is \", mean_squared_error(y_pred,y))\n",
    "np.sqrt(mean_squared_error(y_pred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "AkzVyWwMgPFU",
    "outputId": "35565b8f-0e24-4f93-f316-8cf93e71a81e"
   },
   "outputs": [],
   "source": [
    "#any other line would have a worse result\n",
    "regression_line = lm.intercept_ + lm.coef_[0]*reg_data['AVGGIFT']\n",
    "plt.plot(reg_data['AVGGIFT'], regression_line, c = 'orange')\n",
    "regression_line_2 = lm.intercept_ + 0.8*reg_data['AVGGIFT']\n",
    "plt.plot(reg_data['AVGGIFT'], regression_line_2, c = 'red')\n",
    "regression_line_3 = 10 + lm.coef_[0]*reg_data['AVGGIFT']\n",
    "plt.plot(reg_data['AVGGIFT'], regression_line_3, c = 'green')\n",
    "sns.scatterplot(x='AVGGIFT',y='TARGET_D',data=reg_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE fitted line is \", round(mean_squared_error(regression_line, y),2))\n",
    "print(\"MSE line 2 is      \", round(mean_squared_error(regression_line_2, y),2))\n",
    "print(\"MSE line 3 is      \", round(mean_squared_error(regression_line_3, y),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcVF-tcRjam0"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#let's bring in more variables\n",
    "y = reg_data['TARGET_D']\n",
    "X2 = reg_data.drop(['TARGET_D'], axis=1)\n",
    "lm2 = linear_model.LinearRegression()\n",
    "lm2.fit(X2,y)\n",
    "print(lm2.score(X2,y))\n",
    "y_pred = lm2.predict(X2)\n",
    "print(mean_squared_error(y_pred,y))\n",
    "#results are better, but now we cannot visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CGywtcusRGQK",
    "outputId": "85e3ed9c-b07f-4f6d-9869-39101fa70730"
   },
   "outputs": [],
   "source": [
    "print(lm2.intercept_)\n",
    "print(lm2.coef_)\n",
    "\n",
    "# back to presentation-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_V5xRrWlmSk"
   },
   "source": [
    "# Checking assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCZQHQeJqL_z"
   },
   "outputs": [],
   "source": [
    "# THIS IS PROBABLY THE MOST IMPORTANT LINE IN THIS NOTEBOOK\n",
    "# the best variables are those that have a high correlation with the target (you want to predict, always the y), but low correlation between themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "oARcUjWhRGQN",
    "outputId": "7159aa2c-b3d8-4824-83a1-bde91243342f"
   },
   "outputs": [],
   "source": [
    "correlations_matrix = reg_data.corr()\n",
    "sns.heatmap(correlations_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aef4evjVRGQN"
   },
   "outputs": [],
   "source": [
    "# We can see that there is a very strong positive correlation between IC1 and IC2, IC2 and IC3, IC3 and IC4\n",
    "# using the concept of multicollinearity, lets drop IC1, IC3 and IC4 and keep IC2 as it has the highest corr wit the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkHlkqWjRGQN"
   },
   "outputs": [],
   "source": [
    "reduced_data = reg_data.drop(['IC1', 'IC3', 'IC2'],axis=1)\n",
    "reduced_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "McmgXMcYRGQN",
    "outputId": "4e2987b1-44db-450a-ee30-3520e4e04b7c"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "y = reduced_data['TARGET_D']\n",
    "X3 = reduced_data.drop(['TARGET_D'], axis=1)\n",
    "lm3 = linear_model.LinearRegression()\n",
    "lm3.fit(X3,y)\n",
    "print(lm3.score(X3,y))\n",
    "y_pred=lm3.predict(X3)\n",
    "print(mean_squared_error(y_pred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lesson_1_06.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
